# Bias in the O-information 
Higher-order relationships are one of the central concepts in the science of complex systems. A popular attempt to estimate the higher-order relationships of synergy and redundancy from data is by using the O-information. It is an information-theoretic measure composed of Shannon entropy terms, that quantifies the balance between redundancy and synergy in a system. However, bias is not yet taken into account in the estimation of the O-information of discrete variables. In this paper, we explain where this bias comes from and explore it for fully synergistic, fully redundant and fully independent simulated systems of $n = 3$ variables. Specifically, we explore how the sample size and number of bins affect the bias in the O-information estimation. The main finding is that the O-information of independent systems is severely biased towards synergy if the sample size is smaller than the number of jointly possible observations. This could mean that triplets identified as highly synergistic may in fact be close to independent. A bias approximation based on the Miller-Maddow method is derived for the O-information. We find that for systems of $n = 3$ variables the bias approximation can partially correct for the bias. However, simulations of fully independent systems are still required as null model to provide a benchmark of the biased O-information, based on the data. 
